
@inproceedings{morante_memory-based_2009,
	address = {Boulder, Colorado},
	title = {A memory-based learning approach to event extraction in biomedical texts},
	isbn = {978-1-932432-44-2},
	url = {http://portal.acm.org/citation.cfm?doid=1572340.1572349},
	doi = {10.3115/1572340.1572349},
	abstract = {In this paper we describe the memory-based machine learning system that we submitted to the BioNLP Shared Task on Event Extraction. We modeled the event extraction task using an approach that has been previously applied to other natural language processing tasks like semantic role labeling or negation scope ﬁnding. The results obtained by our system (30.58 F-score in Task 1 and 29.27 in Task 2) suggest that the approach and the system need further adaptation to the complexity involved in extracting biomedical events.},
	language = {en},
	urldate = {2020-07-20},
	booktitle = {Proceedings of the {Workshop} on {BioNLP} {Shared} {Task} - {BioNLP} '09},
	publisher = {Association for Computational Linguistics},
	author = {Morante, Roser and Van Asch, Vincent and Daelemans, Walter},
	year = {2009},
	pages = {59},
	file = {Morante 等。 - 2009 - A memory-based learning approach to event extracti.pdf:files/320/Morante 等。 - 2009 - A memory-based learning approach to event extracti.pdf:application/pdf},
}

@article{deng_meta-learning_2020,
	title = {Meta-{Learning} with {Dynamic}-{Memory}-{Based} {Prototypical} {Network} for {Few}-{Shot} {Event} {Detection}},
	url = {http://arxiv.org/abs/1910.11621},
	doi = {10.1145/3336191.3371796},
	abstract = {Event detection (ED), a sub-task of event extraction, involves identifying triggers and categorizing event mentions. Existing methods primarily rely upon supervised learning and require large-scale labeled event datasets which are unfortunately not readily available in many real-life applications. In this paper, we consider and reformulate the ED task with limited labeled data as a Few-Shot Learning problem. We propose a Dynamic-Memory-Based Prototypical Network (DMB-PN), which exploits Dynamic Memory Network (DMN) to not only learn better prototypes for event types, but also produce more robust sentence encodings for event mentions. Differing from vanilla prototypical networks simply computing event prototypes by averaging, which only consume event mentions once, our model is more robust and is capable of distilling contextual information from event mentions for multiple times due to the multi-hop mechanism of DMNs. The experiments show that DMB-PN not only deals with sample scarcity better than a series of baseline models but also performs more robustly when the variety of event types is relatively large and the instance quantity is extremely small.},
	language = {en},
	urldate = {2020-07-20},
	journal = {Proceedings of the 13th International Conference on Web Search and Data Mining},
	author = {Deng, Shumin and Zhang, Ningyu and Kang, Jiaojian and Zhang, Yichi and Zhang, Wei and Chen, Huajun},
	month = jan,
	year = {2020},
	note = {arXiv: 1910.11621},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval},
	pages = {151--159},
	file = {Deng 等。 - 2020 - Meta-Learning with Dynamic-Memory-Based Prototypic.pdf:files/297/Deng 等。 - 2020 - Meta-Learning with Dynamic-Memory-Based Prototypic.pdf:application/pdf},
}

@inproceedings{huang_zero-shot_2018,
	address = {Melbourne, Australia},
	title = {Zero-{Shot} {Transfer} {Learning} for {Event} {Extraction}},
	url = {http://aclweb.org/anthology/P18-1201},
	doi = {10.18653/v1/P18-1201},
	abstract = {Meaning Representation parsing output. patching is the trigger for the event mention of type Transport Person and in E2, conﬂict is the trigger for the event mention of type Attack. We make use of Abstract Meaning Representations (AMR) (Banarescu et al., 2013) to identify the candidate arguments and construct event mention structures as shown in Figure 2 (top). Figure 2 (bottom) also shows event type structures deﬁned in the Automatic Content Extraction (ACE) guideline.2 We can see that a trigger and its event type name usually have some shared meaning. Furthermore, their structures also tend to be similar: a Transport Person event typically involves a Person as its patient role, while an Attack event involves a Person or Location as an Attacker. This observation matches the theory by Pustejovsky (1991): “the semantics of an event structure can be generalized and mapped to event mention structures in a systematic and predictable way”.},
	language = {en},
	urldate = {2020-07-20},
	booktitle = {Proceedings of the 56th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Huang, Lifu and Ji, Heng and Cho, Kyunghyun and Dagan, Ido and Riedel, Sebastian and Voss, Clare},
	year = {2018},
	pages = {2160--2170},
	file = {Huang 等。 - 2018 - Zero-Shot Transfer Learning for Event Extraction.pdf:files/298/Huang 等。 - 2018 - Zero-Shot Transfer Learning for Event Extraction.pdf:application/pdf},
}


@inproceedings{yang_exploring_2019,
	address = {Florence, Italy},
	title = {Exploring {Pre}-trained {Language} {Models} for {Event} {Extraction} and {Generation}},
	url = {https://www.aclweb.org/anthology/P19-1522},
	doi = {10.18653/v1/P19-1522},
	abstract = {Traditional approaches to the task of ACE event extraction usually depend on manually annotated data, which is often laborious to create and limited in size. Therefore, in addition to the difﬁculty of event extraction itself, insufﬁcient training data hinders the learning process as well. To promote event extraction, we ﬁrst propose an event extraction model to overcome the roles overlap problem by separating the argument prediction in terms of roles. Moreover, to address the problem of insufﬁcient training data, we propose a method to automatically generate labeled data by editing prototypes and screen out generated samples by ranking the quality. Experiments on the ACE2005 dataset demonstrate that our extraction model can surpass most existing extraction methods. Besides, incorporating our generation method exhibits further signiﬁcant improvement. It obtains new state-of-the-art results on the event extraction task, including pushing the F1 score of trigger classiﬁcation to 81.1\%, and the F1 score of argument classiﬁcation to 58.9\%.},
	language = {en},
	urldate = {2020-07-20},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Yang, Sen and Feng, Dawei and Qiao, Linbo and Kan, Zhigang and Li, Dongsheng},
	year = {2019},
	pages = {5284--5294},
	file = {Yang 等。 - 2019 - Exploring Pre-trained Language Models for Event Ex.pdf:files/322/Yang 等。 - 2019 - Exploring Pre-trained Language Models for Event Ex.pdf:application/pdf},
}

@article{lai_exploiting_2020,
	title = {Exploiting the {Matching} {Information} in the {Support} {Set} for {Few} {Shot} {Event} {Classification}},
	volume = {12085},
	url = {http://arxiv.org/abs/2002.05295},
	doi = {10.1007/978-3-030-47436-2_18},
	abstract = {The existing event classiﬁcation (EC) work primarily focuses on the traditional supervised learning setting in which models are unable to extract event mentions of new/unseen event types. Few-shot learning has not been investigated in this area although it enables EC models to extend their operation to unobserved event types. To ﬁll in this gap, in this work, we investigate event classiﬁcation under the few-shot learning setting. We propose a novel training method for this problem that extensively exploit the support set during the training process of a few-shot learning model. In particular, in addition to matching the query example with those in the support set for training, we seek to further match the examples within the support set themselves. This method provides more training signals for the models and can be applied to every metriclearning-based few-shot learning methods. Our extensive experiments on two benchmark EC datasets show that the proposed method can improve the best reported few-shot learning models by up to 10\% on accuracy for event classiﬁcation.},
	language = {en},
	urldate = {2020-07-20},
	journal = {arXiv:2002.05295 [cs, stat]},
	author = {Lai, Viet Dac and Dernoncourt, Franck and Nguyen, Thien Huu},
	year = {2020},
	note = {arXiv: 2002.05295},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {233--245},
	file = {Lai 等。 - 2020 - Exploiting the Matching Information in the Support.pdf:files/323/Lai 等。 - 2020 - Exploiting the Matching Information in the Support.pdf:application/pdf},
}


@article{zheng_doc2edag_2019,
	title = {{Doc2EDAG}: {An} {End}-to-{End} {Document}-level {Framework} for {Chinese} {Financial} {Event} {Extraction}},
	shorttitle = {{Doc2EDAG}},
	url = {http://arxiv.org/abs/1904.07535},
	abstract = {Most existing event extraction (EE) methods merely extract event arguments within the sentence scope. However, such sentence-level EE methods struggle to handle soaring amounts of documents from emerging applications, such as ﬁnance, legislation, health, etc., where event arguments always scatter across different sentences, and even multiple such event mentions frequently co-exist in the same document. To address these challenges, we propose a novel end-to-end model, Doc2EDAG, which can generate an entity-based directed acyclic graph to fulﬁll the document-level EE (DEE) effectively. Moreover, we reformalize a DEE task with the no-trigger-words design to ease document-level event labeling. To demonstrate the effectiveness of Doc2EDAG, we build a large-scale real-world dataset consisting of Chinese ﬁnancial announcements with the challenges mentioned above. Extensive experiments with comprehensive analyses illustrate the superiority of Doc2EDAG over state-of-the-art methods. Data and codes can be found at https://github.com/ dolphin-zs/Doc2EDAG.},
	language = {en},
	urldate = {2020-07-20},
	journal = {arXiv:1904.07535 [cs]},
	author = {Zheng, Shun and Cao, Wei and Xu, Wei and Bian, Jiang},
	month = sep,
	year = {2019},
	note = {arXiv: 1904.07535},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Zheng 等。 - 2019 - Doc2EDAG An End-to-End Document-level Framework f.pdf:files/326/Zheng 等。 - 2019 - Doc2EDAG An End-to-End Document-level Framework f.pdf:application/pdf},
}

@inproceedings{mhamdi_contextualized_2019,
	address = {Hong Kong, China},
	title = {Contextualized {Cross}-{Lingual} {Event} {Trigger} {Extraction} with {Minimal} {Resources}},
	url = {https://www.aclweb.org/anthology/K19-1061},
	doi = {10.18653/v1/K19-1061},
	abstract = {Event trigger extraction is an information extraction task of practical utility, yet it is challenging due to the difﬁculty of disambiguating word sense meaning. Previous approaches rely extensively on hand-crafted language-speciﬁc features and are applied mainly to English for which annotated datasets and Natural Language Processing (NLP) tools are available. However, the availability of such resources varies from one language to another. Recently, contextualized Bidirectional Encoder Representations from Transformers (BERT) models have established state-of-the-art performance for a variety of NLP tasks. However, there has not been much effort in exploring language transfer using BERT for event extraction.},
	language = {en},
	urldate = {2020-07-20},
	booktitle = {Proceedings of the 23rd {Conference} on {Computational} {Natural} {Language} {Learning} ({CoNLL})},
	publisher = {Association for Computational Linguistics},
	author = {M’hamdi, Meryem and Freedman, Marjorie and May, Jonathan},
	year = {2019},
	pages = {656--665},
	file = {M’hamdi 等。 - 2019 - Contextualized Cross-Lingual Event Trigger Extract.pdf:files/328/M’hamdi 等。 - 2019 - Contextualized Cross-Lingual Event Trigger Extract.pdf:application/pdf},
}

@inproceedings{valenzuela-escarcega_domain-independent_2015,
	address = {Beijing, China},
	title = {A {Domain}-independent {Rule}-based {Framework} for {Event} {Extraction}},
	url = {http://aclweb.org/anthology/P15-4022},
	doi = {10.3115/v1/P15-4022},
	abstract = {We describe the design, development, and API of ODIN (Open Domain INformer), a domainindependent, rule-based event extraction (EE) framework. The proposed EE approach is: simple (most events are captured with simple lexico-syntactic patterns), powerful (the language can capture complex constructs, such as events taking other events as arguments, and regular expressions over syntactic graphs), robust (to recover from syntactic parsing errors, syntactic patterns can be freely mixed with surface, token-based patterns), and fast (the runtime environment processes 110 sentences/second in a real-world domain with a grammar of over 200 rules). We used this framework to develop a grammar for the biochemical domain, which approached human performance. Our EE framework is accompanied by a web-based user interface for the rapid development of event grammars and visualization of matches. The ODIN framework and the domain-speciﬁc grammars are available as open-source code.},
	language = {en},
	urldate = {2020-07-20},
	booktitle = {Proceedings of {ACL}-{IJCNLP} 2015 {System} {Demonstrations}},
	publisher = {Association for Computational Linguistics and The Asian Federation of Natural Language Processing},
	author = {Valenzuela-Escárcega, Marco A. and Hahn-Powell, Gus and Surdeanu, Mihai and Hicks, Thomas},
	year = {2015},
	pages = {127--132},
	file = {Valenzuela-Escárcega 等。 - 2015 - A Domain-independent Rule-based Framework for Even.pdf:files/329/Valenzuela-Escárcega 等。 - 2015 - A Domain-independent Rule-based Framework for Even.pdf:application/pdf},
}

@inproceedings{yang_exploring_2019-1,
	address = {Florence, Italy},
	title = {Exploring {Pre}-trained {Language} {Models} for {Event} {Extraction} and {Generation}},
	url = {https://www.aclweb.org/anthology/P19-1522},
	doi = {10.18653/v1/P19-1522},
	abstract = {Traditional approaches to the task of ACE event extraction usually depend on manually annotated data, which is often laborious to create and limited in size. Therefore, in addition to the difﬁculty of event extraction itself, insufﬁcient training data hinders the learning process as well. To promote event extraction, we ﬁrst propose an event extraction model to overcome the roles overlap problem by separating the argument prediction in terms of roles. Moreover, to address the problem of insufﬁcient training data, we propose a method to automatically generate labeled data by editing prototypes and screen out generated samples by ranking the quality. Experiments on the ACE2005 dataset demonstrate that our extraction model can surpass most existing extraction methods. Besides, incorporating our generation method exhibits further signiﬁcant improvement. It obtains new state-of-the-art results on the event extraction task, including pushing the F1 score of trigger classiﬁcation to 81.1\%, and the F1 score of argument classiﬁcation to 58.9\%.},
	language = {en},
	urldate = {2020-07-20},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Yang, Sen and Feng, Dawei and Qiao, Linbo and Kan, Zhigang and Li, Dongsheng},
	year = {2019},
	pages = {5284--5294},
	file = {Yang 等。 - 2019 - Exploring Pre-trained Language Models for Event Ex.pdf:files/330/Yang 等。 - 2019 - Exploring Pre-trained Language Models for Event Ex.pdf:application/pdf},
}

@inproceedings{tian_joint_2019,
	address = {Dalian, China},
	title = {Joint {Extraction} {Model} of {Entities} and {Events}},
	isbn = {978-94-6252-708-9},
	url = {https://www.atlantis-press.com/article/55917256},
	doi = {10.2991/icmeit-19.2019.117},
	abstract = {Joint extraction of entities and events is an important task in information extraction. In order to obtain entities and events in the text simultaneously, in this paper we firstly propose a novel tagging scheme that can transform the joint extraction task to a tagging problem. Then, based on our tagging scheme, we use different end-to-end models to extract entities and events directly and we also propose an improved objective function with different parameters to express the importance of different labels. We conduct experiments on a financial dataset and the results show that our methods are better than other existing models.},
	language = {en},
	urldate = {2020-07-20},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Mechatronics} {Engineering} and {Information} {Technology} ({ICMEIT} 2019)},
	publisher = {Atlantis Press},
	author = {Tian, Can and Zhao, Yawei and Ren, Liang},
	year = {2019},
	file = {Tian 等。 - 2019 - Joint Extraction Model of Entities and Events.pdf:files/331/Tian 等。 - 2019 - Joint Extraction Model of Entities and Events.pdf:application/pdf},
}

@inproceedings{wang_hmeae_2019,
	address = {Hong Kong, China},
	title = {{HMEAE}: {Hierarchical} {Modular} {Event} {Argument} {Extraction}},
	shorttitle = {{HMEAE}},
	url = {https://www.aclweb.org/anthology/D19-1584},
	doi = {10.18653/v1/D19-1584},
	abstract = {Existing event extraction methods classify each argument role independently, ignoring the conceptual correlations between different argument roles. In this paper, we propose a Hierarchical Modular Event Argument Extraction (HMEAE) model, to provide effective inductive bias from the concept hierarchy of event argument roles. Speciﬁcally, we design a neural module network for each basic unit of the concept hierarchy, and then hierarchically compose relevant unit modules with logical operations into a role-oriented modular network to classify a speciﬁc argument role. As many argument roles share the same high-level unit module, their correlation can be utilized to extract speciﬁc event arguments better. Experiments on real-world datasets show that HMEAE can effectively leverage useful knowledge from the concept hierarchy and signiﬁcantly outperform the stateof-the-art baselines. The source code can be obtained from https://github.com/ thunlp/HMEAE.},
	language = {en},
	urldate = {2020-07-20},
	booktitle = {Proceedings of the 2019 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and the 9th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({EMNLP}-{IJCNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Wang, Xiaozhi and Wang, Ziqi and Han, Xu and Liu, Zhiyuan and Li, Juanzi and Li, Peng and Sun, Maosong and Zhou, Jie and Ren, Xiang},
	year = {2019},
	pages = {5776--5782},
	file = {Wang 等。 - 2019 - HMEAE Hierarchical Modular Event Argument Extract.pdf:files/332/Wang 等。 - 2019 - HMEAE Hierarchical Modular Event Argument Extract.pdf:application/pdf},
}


@article{satyapanich_casie_2020,
	title = {{CASIE}: {Extracting} {Cybersecurity} {Event} {Information} from {Text}},
	volume = {34},
	issn = {2374-3468, 2159-5399},
	shorttitle = {{CASIE}},
	url = {https://aaai.org/ojs/index.php/AAAI/article/view/6401},
	doi = {10.1609/aaai.v34i05.6401},
	abstract = {We present CASIE, a system that extracts information about cybersecurity events from text and populates a semantic model, with the ultimate goal of integration into a knowledge graph of cybersecurity data. It was trained on a new corpus of 1,000 English news articles from 2017–2019 that are labeled with rich, event-based annotations and that covers both cyberattack and vulnerability-related events. Our model deﬁnes ﬁve event subtypes along with their semantic roles and 20 event-relevant argument types (e.g., ﬁle, device, software, money). CASIE uses different deep neural networks approaches with attention and can incorporate rich linguistic features and word embeddings. We have conducted experiments on each component in the event detection pipeline and the results show that each subsystem performs well.},
	language = {en},
	number = {05},
	urldate = {2020-07-20},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Satyapanich, Taneeya and Ferraro, Francis and Finin, Tim},
	month = apr,
	year = {2020},
	pages = {8749--8757},
	file = {Satyapanich 等。 - 2020 - CASIE Extracting Cybersecurity Event Information .pdf:files/334/Satyapanich 等。 - 2020 - CASIE Extracting Cybersecurity Event Information .pdf:application/pdf},
}

@article{zhang_joint_2019,
	title = {Joint {Entity} and {Event} {Extraction} with {Generative} {Adversarial} {Imitation} {Learning}},
	volume = {1},
	issn = {2641-435X},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/dint_a_00014},
	doi = {10.1162/dint_a_00014},
	abstract = {We propose a new framework for entity and event extraction based on generative adversarial imitation learning—an inverse reinforcement learning method using a generative adversarial network (GAN). We assume that instances and labels yield to various extents of difficulty and the gains and penalties (rewards) are expected to be diverse. We utilize discriminators to estimate proper rewards according to the difference between the labels committed by the ground-truth (expert) and the extractor (agent). Our experiments demonstrate that the proposed framework outperforms state-of-the-art methods.},
	language = {en},
	number = {2},
	urldate = {2020-07-20},
	journal = {Data Intelligence},
	author = {Zhang, Tongtao and Ji, Heng and Sil, Avirup},
	month = apr,
	year = {2019},
	pages = {99--120},
	file = {Zhang 等。 - 2019 - Joint Entity and Event Extraction with Generative .pdf:files/335/Zhang 等。 - 2019 - Joint Entity and Event Extraction with Generative .pdf:application/pdf},
}

@article{liu_jointly_2018,
	title = {Jointly {Multiple} {Events} {Extraction} via {Attention}-based {Graph} {Information} {Aggregation}},
	url = {http://arxiv.org/abs/1809.09078},
	abstract = {Event extraction is of practical utility in natural language processing. In the real world, it is a common phenomenon that multiple events existing in the same sentence, where extracting them are more difﬁcult than extracting a single event. Previous works on modeling the associations between events by sequential modeling methods suffer a lot from the low efﬁciency in capturing very long-range dependencies. In this paper, we propose a novel Jointly Multiple Events Extraction (JMEE) framework to jointly extract multiple event triggers and arguments by introducing syntactic shortcut arcs to enhance information ﬂow and attention-based graph convolution networks to model graph information. The experiment results demonstrate that our proposed framework achieves competitive results compared with state-of-the-art methods.},
	language = {en},
	urldate = {2020-07-20},
	journal = {arXiv:1809.09078 [cs]},
	author = {Liu, Xiao and Luo, Zhunchen and Huang, Heyan},
	month = oct,
	year = {2018},
	note = {arXiv: 1809.09078},
	keywords = {Computer Science - Computation and Language},
	file = {Liu 等。 - 2018 - Jointly Multiple Events Extraction via Attention-b.pdf:files/336/Liu 等。 - 2018 - Jointly Multiple Events Extraction via Attention-b.pdf:application/pdf},
}

@inproceedings{nguyen_joint_2016,
	address = {San Diego, California},
	title = {Joint {Event} {Extraction} via {Recurrent} {Neural} {Networks}},
	url = {http://aclweb.org/anthology/N16-1034},
	doi = {10.18653/v1/N16-1034},
	abstract = {Event extraction is a particularly challenging problem in information extraction. The stateof-the-art models for this problem have either applied convolutional neural networks in a pipelined framework (Chen et al., 2015) or followed the joint architecture via structured prediction with rich local and global features (Li et al., 2013). The former is able to learn hidden feature representations automatically from data based on the continuous and generalized representations of words. The latter, on the other hand, is capable of mitigating the error propagation problem of the pipelined approach and exploiting the inter-dependencies between event triggers and argument roles via discrete structures. In this work, we propose to do event extraction in a joint framework with bidirectional recurrent neural networks, thereby beneﬁting from the advantages of the two models as well as addressing issues inherent in the existing approaches. We systematically investigate different memory features for the joint model and demonstrate that the proposed model achieves the state-of-the-art performance on the ACE 2005 dataset.},
	language = {en},
	urldate = {2020-07-20},
	booktitle = {Proceedings of the 2016 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Nguyen, Thien Huu and Cho, Kyunghyun and Grishman, Ralph},
	year = {2016},
	pages = {300--309},
	file = {Nguyen 等。 - 2016 - Joint Event Extraction via Recurrent Neural Networ.pdf:files/338/Nguyen 等。 - 2016 - Joint Event Extraction via Recurrent Neural Networ.pdf:application/pdf},
}

@article{lai_exploiting_2020-1,
	title = {Exploiting the {Matching} {Information} in the {Support} {Set} for {Few} {Shot} {Event} {Classification}},
	volume = {12085},
	url = {http://arxiv.org/abs/2002.05295},
	doi = {10.1007/978-3-030-47436-2_18},
	abstract = {The existing event classiﬁcation (EC) work primarily focuses on the traditional supervised learning setting in which models are unable to extract event mentions of new/unseen event types. Few-shot learning has not been investigated in this area although it enables EC models to extend their operation to unobserved event types. To ﬁll in this gap, in this work, we investigate event classiﬁcation under the few-shot learning setting. We propose a novel training method for this problem that extensively exploit the support set during the training process of a few-shot learning model. In particular, in addition to matching the query example with those in the support set for training, we seek to further match the examples within the support set themselves. This method provides more training signals for the models and can be applied to every metriclearning-based few-shot learning methods. Our extensive experiments on two benchmark EC datasets show that the proposed method can improve the best reported few-shot learning models by up to 10\% on accuracy for event classiﬁcation.},
	language = {en},
	urldate = {2020-07-20},
	journal = {arXiv:2002.05295 [cs, stat]},
	author = {Lai, Viet Dac and Dernoncourt, Franck and Nguyen, Thien Huu},
	year = {2020},
	note = {arXiv: 2002.05295},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {233--245},
	file = {Lai 等。 - 2020 - Exploiting the Matching Information in the Support.pdf:files/339/Lai 等。 - 2020 - Exploiting the Matching Information in the Support.pdf:application/pdf},
}




@inproceedings{chen_automatically_2017,
	address = {Vancouver, Canada},
	title = {Automatically {Labeled} {Data} {Generation} for {Large} {Scale} {Event} {Extraction}},
	url = {http://aclweb.org/anthology/P17-1038},
	doi = {10.18653/v1/P17-1038},
	abstract = {Modern models of event extraction for tasks like ACE are based on supervised learning of events from small hand-labeled data. However, hand-labeled training data is expensive to produce, in low coverage of event types, and limited in size, which makes supervised methods hard to extract large scale of events for knowledge base population. To solve the data labeling problem, we propose to automatically label training data for event extraction via world knowledge and linguistic knowledge, which can detect key arguments and trigger words for each event type and employ them to label events in texts automatically. The experimental results show that the quality of our large scale automatically labeled data is competitive with elaborately human-labeled data. And our automatically labeled data can incorporate with human-labeled data, then improve the performance of models learned from these data.},
	language = {en},
	urldate = {2020-07-20},
	booktitle = {Proceedings of the 55th {Annual} {Meeting} of the {Association} for           {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Chen, Yubo and Liu, Shulin and Zhang, Xiang and Liu, Kang and Zhao, Jun},
	year = {2017},
	pages = {409--419},
	file = {Chen 等。 - 2017 - Automatically Labeled Data Generation for Large Sc.pdf:files/342/Chen 等。 - 2017 - Automatically Labeled Data Generation for Large Sc.pdf:application/pdf},
}



@article{deng_meta-learning_2020-1,
	title = {Meta-{Learning} with {Dynamic}-{Memory}-{Based} {Prototypical} {Network} for {Few}-{Shot} {Event} {Detection}},
	url = {http://arxiv.org/abs/1910.11621},
	doi = {10.1145/3336191.3371796},
	abstract = {Event detection (ED), a sub-task of event extraction, involves identifying triggers and categorizing event mentions. Existing methods primarily rely upon supervised learning and require large-scale labeled event datasets which are unfortunately not readily available in many real-life applications. In this paper, we consider and reformulate the ED task with limited labeled data as a Few-Shot Learning problem. We propose a Dynamic-Memory-Based Prototypical Network (DMB-PN), which exploits Dynamic Memory Network (DMN) to not only learn better prototypes for event types, but also produce more robust sentence encodings for event mentions. Differing from vanilla prototypical networks simply computing event prototypes by averaging, which only consume event mentions once, our model is more robust and is capable of distilling contextual information from event mentions for multiple times due to the multi-hop mechanism of DMNs. The experiments show that DMB-PN not only deals with sample scarcity better than a series of baseline models but also performs more robustly when the variety of event types is relatively large and the instance quantity is extremely small.},
	language = {en},
	urldate = {2020-07-20},
	journal = {Proceedings of the 13th International Conference on Web Search and Data Mining},
	author = {Deng, Shumin and Zhang, Ningyu and Kang, Jiaojian and Zhang, Yichi and Zhang, Wei and Chen, Huajun},
	month = jan,
	year = {2020},
	note = {arXiv: 1910.11621},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval},
	pages = {151--159},
	file = {Deng 等。 - 2020 - Meta-Learning with Dynamic-Memory-Based Prototypic.pdf:files/345/Deng 等。 - 2020 - Meta-Learning with Dynamic-Memory-Based Prototypic.pdf:application/pdf},
}


@article{zhang_joint_2019-1,
	title = {Joint {Entity} and {Event} {Extraction} with {Generative} {Adversarial} {Imitation} {Learning}},
	volume = {1},
	issn = {2641-435X},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/dint_a_00014},
	doi = {10.1162/dint_a_00014},
	abstract = {We propose a new framework for entity and event extraction based on generative adversarial imitation learning—an inverse reinforcement learning method using a generative adversarial network (GAN). We assume that instances and labels yield to various extents of difficulty and the gains and penalties (rewards) are expected to be diverse. We utilize discriminators to estimate proper rewards according to the difference between the labels committed by the ground-truth (expert) and the extractor (agent). Our experiments demonstrate that the proposed framework outperforms state-of-the-art methods.},
	language = {en},
	number = {2},
	urldate = {2020-07-20},
	journal = {Data Intelligence},
	author = {Zhang, Tongtao and Ji, Heng and Sil, Avirup},
	month = apr,
	year = {2019},
	pages = {99--120},
	file = {Zhang 等。 - 2019 - Joint Entity and Event Extraction with Generative .pdf:files/348/Zhang 等。 - 2019 - Joint Entity and Event Extraction with Generative .pdf:application/pdf},
}

@article{lin_nugget_2018,
	title = {Nugget {Proposal} {Networks} for {Chinese} {Event} {Detection}},
	url = {http://arxiv.org/abs/1805.00249},
	abstract = {Neural network based models commonly regard event detection as a word-wise classiﬁcation task, which suffer from the mismatch problem between words and event triggers, especially in languages without natural word delimiters such as Chinese. In this paper, we propose Nugget Proposal Networks (NPNs), which can solve the word-trigger mismatch problem by directly proposing entire trigger nuggets centered at each character regardless of word boundaries. Speciﬁcally, NPNs perform event detection in a character-wise paradigm, where a hybrid representation for each character is ﬁrst learned to capture both structural and semantic information from both characters and words. Then based on learned representations, trigger nuggets are proposed and categorized by exploiting character compositional structures of Chinese event triggers. Experiments on both ACE2005 and TAC KBP 2017 datasets show that NPNs signiﬁcantly outperform the state-of-the-art methods.},
	language = {en},
	urldate = {2020-07-20},
	journal = {arXiv:1805.00249 [cs]},
	author = {Lin, Hongyu and Lu, Yaojie and Han, Xianpei and Sun, Le},
	month = may,
	year = {2018},
	note = {arXiv: 1805.00249},
	keywords = {Computer Science - Computation and Language},
	file = {Lin 等。 - 2018 - Nugget Proposal Networks for Chinese Event Detecti.pdf:files/349/Lin 等。 - 2018 - Nugget Proposal Networks for Chinese Event Detecti.pdf:application/pdf},
}

@inproceedings{nguyen_modeling_2016,
	address = {Austin, Texas},
	title = {Modeling {Skip}-{Grams} for {Event} {Detection} with {Convolutional} {Neural} {Networks}},
	url = {http://aclweb.org/anthology/D16-1085},
	doi = {10.18653/v1/D16-1085},
	abstract = {Convolutional neural networks (CNN) have achieved the top performance for event detection due to their capacity to induce the underlying structures of the k-grams in the sentences. However, the current CNN-based event detectors only model the consecutive k-grams and ignore the non-consecutive kgrams that might involve important structures for event detection. In this work, we propose to improve the current CNN models for ED by introducing the non-consecutive convolution. Our systematic evaluation on both the general setting and the domain adaptation setting demonstrates the effectiveness of the nonconsecutive CNN model, leading to the significant performance improvement over the current state-of-the-art systems.},
	language = {en},
	urldate = {2020-07-20},
	booktitle = {Proceedings of the 2016 {Conference} on {Empirical} {Methods} in {Natural}           {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Nguyen, Thien Huu and Grishman, Ralph},
	year = {2016},
	pages = {886--891},
	file = {Nguyen 和 Grishman - 2016 - Modeling Skip-Grams for Event Detection with Convo.pdf:files/351/Nguyen 和 Grishman - 2016 - Modeling Skip-Grams for Event Detection with Convo.pdf:application/pdf},
}

@inproceedings{nguyen_event_2015,
	address = {Beijing, China},
	title = {Event {Detection} and {Domain} {Adaptation} with {Convolutional} {Neural} {Networks}},
	url = {http://aclweb.org/anthology/P15-2060},
	doi = {10.3115/v1/P15-2060},
	abstract = {We study the event detection problem using convolutional neural networks (CNNs) that overcome the two fundamental limitations of the traditional feature-based approaches to this task: complicated feature engineering for rich feature sets and error propagation from the preceding stages which generate these features. The experimental results show that the CNNs outperform the best reported feature-based systems in the general setting as well as the domain adaptation setting without resorting to extensive external resources.},
	language = {en},
	urldate = {2020-07-20},
	booktitle = {Proceedings of the 53rd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 7th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Nguyen, Thien Huu and Grishman, Ralph},
	year = {2015},
	pages = {365--371},
	file = {Nguyen 和 Grishman - 2015 - Event Detection and Domain Adaptation with Convolu.pdf:files/352/Nguyen 和 Grishman - 2015 - Event Detection and Domain Adaptation with Convolu.pdf:application/pdf},
}

@incollection{lauw_exploiting_2020,
	address = {Cham},
	title = {Exploiting the {Matching} {Information} in the {Support} {Set} for {Few} {Shot} {Event} {Classification}},
	volume = {12085},
	isbn = {978-3-030-47435-5 978-3-030-47436-2},
	url = {http://link.springer.com/10.1007/978-3-030-47436-2_18},
	abstract = {The existing event classiﬁcation (EC) work primarily focuses on the traditional supervised learning setting in which models are unable to extract event mentions of new/unseen event types. Few-shot learning has not been investigated in this area although it enables EC models to extend their operation to unobserved event types. To ﬁll in this gap, in this work, we investigate event classiﬁcation under the few-shot learning setting. We propose a novel training method for this problem that extensively exploit the support set during the training process of a few-shot learning model. In particular, in addition to matching the query example with those in the support set for training, we seek to further match the examples within the support set themselves. This method provides more training signals for the models and can be applied to every metriclearning-based few-shot learning methods. Our extensive experiments on two benchmark EC datasets show that the proposed method can improve the best reported few-shot learning models by up to 10\% on accuracy for event classiﬁcation.},
	language = {en},
	urldate = {2020-07-20},
	booktitle = {Advances in {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Springer International Publishing},
	author = {Lai, Viet Dac and Dernoncourt, Franck and Nguyen, Thien Huu},
	editor = {Lauw, Hady W. and Wong, Raymond Chi-Wing and Ntoulas, Alexandros and Lim, Ee-Peng and Ng, See-Kiong and Pan, Sinno Jialin},
	year = {2020},
	doi = {10.1007/978-3-030-47436-2_18},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {233--245},
	file = {Lai 等。 - 2020 - Exploiting the Matching Information in the Support.pdf:files/353/Lai 等。 - 2020 - Exploiting the Matching Information in the Support.pdf:application/pdf},
}

@inproceedings{ein-dor_financial_2019,
	address = {Hong Kong},
	title = {Financial {Event} {Extraction} {Using} {Wikipedia}-{Based} {Weak} {Supervision}},
	url = {https://www.aclweb.org/anthology/D19-5102},
	doi = {10.18653/v1/D19-5102},
	abstract = {Extraction of ﬁnancial and economic events from text has previously been done mostly using rule-based methods, with more recent works employing machine learning techniques. This work is in line with this latter approach, leveraging relevant Wikipedia sections to extract weak labels for sentences describing economic events. Whereas previous weakly supervised approaches required a knowledgebase of such events, or corresponding ﬁnancial ﬁgures, our approach requires no such additional data, and can be employed to extract economic events related to companies which are not even mentioned in the training data.},
	language = {en},
	urldate = {2020-07-20},
	booktitle = {Proceedings of the {Second} {Workshop} on {Economics} and {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Ein-Dor, Liat and Gera, Ariel and Toledo-Ronen, Orith and Halfon, Alon and Sznajder, Benjamin and Dankin, Lena and Bilu, Yonatan and Katz, Yoav and Slonim, Noam},
	year = {2019},
	pages = {10--15},
	file = {Ein-Dor 等。 - 2019 - Financial Event Extraction Using Wikipedia-Based W.pdf:files/354/Ein-Dor 等。 - 2019 - Financial Event Extraction Using Wikipedia-Based W.pdf:application/pdf},
}

@inproceedings{tian_joint_2019-1,
	address = {Dalian, China},
	title = {Joint {Extraction} {Model} of {Entities} and {Events}},
	isbn = {978-94-6252-708-9},
	url = {https://www.atlantis-press.com/article/55917256},
	doi = {10.2991/icmeit-19.2019.117},
	abstract = {Joint extraction of entities and events is an important task in information extraction. In order to obtain entities and events in the text simultaneously, in this paper we firstly propose a novel tagging scheme that can transform the joint extraction task to a tagging problem. Then, based on our tagging scheme, we use different end-to-end models to extract entities and events directly and we also propose an improved objective function with different parameters to express the importance of different labels. We conduct experiments on a financial dataset and the results show that our methods are better than other existing models.},
	language = {en},
	urldate = {2020-07-20},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Mechatronics} {Engineering} and {Information} {Technology} ({ICMEIT} 2019)},
	publisher = {Atlantis Press},
	author = {Tian, Can and Zhao, Yawei and Ren, Liang},
	year = {2019},
	file = {Tian 等。 - 2019 - Joint Extraction Model of Entities and Events.pdf:files/355/Tian 等。 - 2019 - Joint Extraction Model of Entities and Events.pdf:application/pdf},
}

@inproceedings{mhamdi_contextualized_2019-1,
	address = {Hong Kong, China},
	title = {Contextualized {Cross}-{Lingual} {Event} {Trigger} {Extraction} with {Minimal} {Resources}},
	url = {https://www.aclweb.org/anthology/K19-1061},
	doi = {10.18653/v1/K19-1061},
	abstract = {Event trigger extraction is an information extraction task of practical utility, yet it is challenging due to the difﬁculty of disambiguating word sense meaning. Previous approaches rely extensively on hand-crafted language-speciﬁc features and are applied mainly to English for which annotated datasets and Natural Language Processing (NLP) tools are available. However, the availability of such resources varies from one language to another. Recently, contextualized Bidirectional Encoder Representations from Transformers (BERT) models have established state-of-the-art performance for a variety of NLP tasks. However, there has not been much effort in exploring language transfer using BERT for event extraction.},
	language = {en},
	urldate = {2020-07-20},
	booktitle = {Proceedings of the 23rd {Conference} on {Computational} {Natural} {Language} {Learning} ({CoNLL})},
	publisher = {Association for Computational Linguistics},
	author = {M’hamdi, Meryem and Freedman, Marjorie and May, Jonathan},
	year = {2019},
	pages = {656--665},
	file = {M’hamdi 等。 - 2019 - Contextualized Cross-Lingual Event Trigger Extract.pdf:files/356/M’hamdi 等。 - 2019 - Contextualized Cross-Lingual Event Trigger Extract.pdf:application/pdf},
}

@inproceedings{kadowaki_event_2019,
	address = {Hong Kong, China},
	title = {Event {Causality} {Recognition} {Exploiting} {Multiple} {Annotators}’ {Judgments} and {Background} {Knowledge}},
	url = {https://www.aclweb.org/anthology/D19-1590},
	doi = {10.18653/v1/D19-1590},
	abstract = {We propose new BERT-based methods for recognizing event causality such as “smoke cigarettes” → “die of lung cancer” written in web texts. In our methods, we grasp each annotator’s policy by training multiple classiﬁers, each of which predicts the labels given by a single annotator, and combine the resulting classiﬁers’ outputs to predict the ﬁnal labels determined by majority vote. Furthermore, we investigate the effect of supplying background knowledge to our classiﬁers. Since BERT models are pre-trained with a large corpus, some sort of background knowledge for event causality may be learned during pre-training. Our experiments with a Japanese dataset suggest that this is actually the case: Performance improved when we pretrained the BERT models with web texts containing a large number of event causalities instead of Wikipedia articles or randomly sampled web texts. However, this effect was limited. Therefore, we further improved performance by simply adding texts related to an input causality candidate as background knowledge to the input of the BERT models. We believe these ﬁndings indicate a promising future research direction.},
	language = {en},
	urldate = {2020-07-20},
	booktitle = {Proceedings of the 2019 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and the 9th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({EMNLP}-{IJCNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Kadowaki, Kazuma and Iida, Ryu and Torisawa, Kentaro and Oh, Jong-Hoon and Kloetzer, Julien},
	year = {2019},
	pages = {5815--5821},
	file = {Kadowaki 等。 - 2019 - Event Causality Recognition Exploiting Multiple An.pdf:files/357/Kadowaki 等。 - 2019 - Event Causality Recognition Exploiting Multiple An.pdf:application/pdf},
}

@article{xiao_cail2018_2018,
	title = {{CAIL2018}: {A} {Large}-{Scale} {Legal} {Dataset} for {Judgment} {Prediction}},
	shorttitle = {{CAIL2018}},
	url = {http://arxiv.org/abs/1807.02478},
	abstract = {In this paper, we introduce the Chinese AI and Law challenge dataset (CAIL2018), the ﬁrst large-scale Chinese legal dataset for judgment prediction. CAIL2018 contains more than 2.6 million criminal cases published by the Supreme People’s Court of China, which are several times larger than other datasets in existing works on judgment prediction. Moreover, the annotations of judgment results are more detailed and rich. It consists of applicable law articles, charges, and prison terms, which are expected to be inferred according to the fact descriptions of cases. For comparison, we implement several conventional text classiﬁcation baselines for judgment prediction and experimental results show that it is still a challenge for current models to predict the judgment results of legal cases, especially on prison terms. To help the researchers make improvements on legal judgment prediction, both CAIL2018 and baselines will be released after the CAIL competition1.},
	language = {en},
	urldate = {2020-07-20},
	journal = {arXiv:1807.02478 [cs]},
	author = {Xiao, Chaojun and Zhong, Haoxi and Guo, Zhipeng and Tu, Cunchao and Liu, Zhiyuan and Sun, Maosong and Feng, Yansong and Han, Xianpei and Hu, Zhen and Wang, Heng and Xu, Jianfeng},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.02478},
	keywords = {Computer Science - Computation and Language},
	file = {Xiao 等。 - 2018 - CAIL2018 A Large-Scale Legal Dataset for Judgment.pdf:files/358/Xiao 等。 - 2018 - CAIL2018 A Large-Scale Legal Dataset for Judgment.pdf:application/pdf},
}

@article{feng_probing_2020,
	title = {Probing and {Fine}-tuning {Reading} {Comprehension} {Models} for {Few}-shot {Event} {Extraction}},
	url = {http://arxiv.org/abs/2010.11325},
	abstract = {We study the problem of event extraction from text data, which requires both detecting target event types and their arguments. Typically, both the event detection and argument detection subtasks are formulated as supervised sequence labeling problems. We argue that the event extraction models so trained are inherently labelhungry, and can generalize poorly across domains and text genres. We propose a reading comprehension framework for event extraction. Specifically, we formulate event detection as a textual entailment prediction problem, and argument detection as a question answering problem. By constructing proper query templates, our approach can effectively distill rich knowledge about tasks and label semantics from pretrained reading comprehension models. Moreover, our model can be fine-tuned with a small amount of data to boost its performance. Our experiment results show that our method performs strongly for zero-shot and few-shot event extraction, and it achieves state-of-the-art performance on the ACE 2005 benchmark when trained with full supervision.},
	language = {en},
	urldate = {2020-11-01},
	journal = {arXiv:2010.11325 [cs]},
	author = {Feng, Rui and Yuan, Jie and Zhang, Chao},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.11325},
	keywords = {Computer Science - Computation and Language},
	file = {Feng 等。 - 2020 - Probing and Fine-tuning Reading Comprehension Mode.pdf:files/183/Feng 等。 - 2020 - Probing and Fine-tuning Reading Comprehension Mode.pdf:application/pdf},
}


@inproceedings{nguyen_two-stage_2016,
	address = {Berlin, Germany},
	title = {A {Two}-stage {Approach} for {Extending} {Event} {Detection} to {New} {Types} via {Neural} {Networks}},
	url = {http://aclweb.org/anthology/W16-1618},
	doi = {10.18653/v1/W16-1618},
	abstract = {We study the event detection problem in the new type extension setting. In particular, our task involves identifying the event instances of a target type that is only speciﬁed by a small set of seed instances in text. We want to exploit the large amount of training data available for the other event types to improve the performance of this task. We compare the convolutional neural network model and the feature-based method in this type extension setting to investigate their effectiveness. In addition, we propose a two-stage training algorithm for neural networks that effectively transfers knowledge from the other event types to the target type. The experimental results show that the proposed algorithm outperforms strong baselines for this task.},
	language = {en},
	urldate = {2020-09-30},
	booktitle = {Proceedings of the 1st {Workshop} on {Representation} {Learning} for {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Nguyen, Thien Huu and Fu, Lisheng and Cho, Kyunghyun and Grishman, Ralph},
	year = {2016},
	pages = {158--165},
	file = {Nguyen 等。 - 2016 - A Two-stage Approach for Extending Event Detection.pdf:files/207/Nguyen 等。 - 2016 - A Two-stage Approach for Extending Event Detection.pdf:application/pdf},
}

@inproceedings{liu_leveraging_2016,
	address = {Berlin, Germany},
	title = {Leveraging {FrameNet} to {Improve} {Automatic} {Event} {Detection}},
	url = {http://aclweb.org/anthology/P16-1201},
	doi = {10.18653/v1/P16-1201},
	abstract = {Frames deﬁned in FrameNet (FN) share highly similar structures with events in ACE event extraction program. An event in ACE is composed of an event trigger and a set of arguments. Analogously, a frame in FN is composed of a lexical unit and a set of frame elements, which play similar roles as triggers and arguments of ACE events respectively. Besides having similar structures, many frames in FN actually express certain types of events. The above observations motivate us to explore whether there exists a good mapping from frames to event-types and if it is possible to improve event detection by using FN. In this paper, we propose a global inference approach to detect events in FN. Further, based on the detected results, we analyze possible mappings from frames to event-types. Finally, we improve the performance of event detection and achieve a new state-of-the-art result by using the events automatically detected from FN.},
	language = {en},
	urldate = {2020-09-08},
	booktitle = {Proceedings of the 54th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Shulin and Chen, Yubo and He, Shizhu and Liu, Kang and Zhao, Jun},
	year = {2016},
	pages = {2134--2143},
	file = {Liu 等。 - 2016 - Leveraging FrameNet to Improve Automatic Event Det.pdf:files/212/Liu 等。 - 2016 - Leveraging FrameNet to Improve Automatic Event Det.pdf:application/pdf},
}

@article{chambers_template-based_nodate,
	title = {Template-{Based} {Information} {Extraction} without the {Templates}},
	abstract = {Standard algorithms for template-based information extraction (IE) require predeﬁned template schemas, and often labeled data, to learn to extract their slot ﬁllers (e.g., an embassy is the Target of a Bombing template). This paper describes an approach to template-based IE that removes this requirement and performs extraction without knowing the template structure in advance. Our algorithm instead learns the template structure automatically from raw text, inducing template schemas as sets of linked events (e.g., bombings include detonate, set off, and destroy events) associated with semantic roles. We also solve the standard IE task, using the induced syntactic patterns to extract role ﬁllers from speciﬁc documents. We evaluate on the MUC-4 terrorism dataset and show that we induce template structure very similar to handcreated gold structure, and we extract role ﬁllers with an F1 score of .40, approaching the performance of algorithms that require full knowledge of the templates.},
	language = {en},
	author = {Chambers, Nathanael and Jurafsky, Dan},
	pages = {11},
	year = {2011}
	file = {Chambers 和 Jurafsky - Template-Based Information Extraction without the .pdf:files/213/Chambers 和 Jurafsky - Template-Based Information Extraction without the .pdf:application/pdf},
}

@inproceedings{arendarenko_ontology-based_2012,
	title = {Ontology-based information and event extraction for business intelligence},
	booktitle = {International {Conference} on {Artificial} {Intelligence}: {Methodology}, {Systems}, and {Applications}},
	publisher = {Springer},
	author = {Arendarenko, Ernest and Kakkonen, Tuomo},
	year = {2012},
	pages = {89--102},
	file = {Snapshot:files/222/978-3-642-33185-5_10.html:text/html;Arendarenko_Kakkonen_2012_Ontology-based information and event extraction for business intelligence.pdf:files/223/Arendarenko_Kakkonen_2012_Ontology-based information and event extraction for business intelligence.pdf:application/pdf},
}

@inproceedings{ding_event_2019,
	address = {Hong Kong, China},
	title = {Event {Detection} with {Trigger}-{Aware} {Lattice} {Neural} {Network}},
	url = {https://www.aclweb.org/anthology/D19-1033},
	doi = {10.18653/v1/D19-1033},
	abstract = {Event detection (ED) aims to locate trigger words in raw text and then classify them into correct event types. In this task, neural network based models became mainstream in recent years. However, two problems arise when it comes to languages without natural delimiters, such as Chinese. First, word-based models severely suffer from the problem of wordtrigger mismatch, limiting the performance of the methods. In addition, even if trigger words could be accurately located, the ambiguity of polysemy of triggers could still affect the trigger classiﬁcation stage. To address the two issues simultaneously, we propose the Trigger-aware Lattice Neural Network (TLNN). (1) The framework dynamically incorporates word and character information so that the trigger-word mismatch issue can be avoided. (2) Moreover, for polysemous characters and words, we model all senses of them with the help of an external linguistic knowledge base, so as to alleviate the problem of ambiguous triggers. Experiments on two benchmark datasets show that our model could effectively tackle the two issues and outperforms previous state-of-the-art methods signiﬁcantly, giving the best results. The source code of this paper can be obtained from https://github.com/thunlp/TLNN.},
	language = {en},
	urldate = {2020-08-20},
	booktitle = {Proceedings of the 2019 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and the 9th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({EMNLP}-{IJCNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Ding, Ning and Li, Ziran and Liu, Zhiyuan and Zheng, Haitao and Lin, Zibo},
	year = {2019},
	pages = {347--356},
	file = {Ding 等。 - 2019 - Event Detection with Trigger-Aware Lattice Neural .pdf:files/224/Ding 等。 - 2019 - Event Detection with Trigger-Aware Lattice Neural .pdf:application/pdf},
}

@inproceedings{li_chinese_2019,
	address = {Florence, Italy},
	title = {Chinese {Relation} {Extraction} with {Multi}-{Grained} {Information} and {External} {Linguistic} {Knowledge}},
	url = {https://www.aclweb.org/anthology/P19-1430},
	doi = {10.18653/v1/P19-1430},
	abstract = {Chinese relation extraction is conducted using neural networks with either character-based or word-based inputs, and most existing methods typically suffer from segmentation errors and ambiguity of polysemy. To address the issues, we propose a multi-grained lattice framework (MG lattice) for Chinese relation extraction to take advantage of multi-grained language information and external linguistic knowledge. In this framework, (1) we incorporate word-level information into character sequence inputs so that segmentation errors can be avoided. (2) We also model multiple senses of polysemous words with the help of external linguistic knowledge, so as to alleviate polysemy ambiguity. Experiments on three realworld datasets in distinct domains show consistent and signiﬁcant superiority and robustness of our model, as compared with other baselines. The source code of this paper can be obtained from https://github.com/ thunlp/Chinese\_NRE.},
	language = {en},
	urldate = {2020-08-20},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Li, Ziran and Ding, Ning and Liu, Zhiyuan and Zheng, Haitao and Shen, Ying},
	year = {2019},
	pages = {4377--4386},
	file = {Li 等。 - 2019 - Chinese Relation Extraction with Multi-Grained Inf.pdf:files/225/Li 等。 - 2019 - Chinese Relation Extraction with Multi-Grained Inf.pdf:application/pdf},
}

@article{li_biomedical_nodate,
	title = {Biomedical {Event} {Extraction} based on {Knowledge}-driven {Tree}-{LSTM}},
	abstract = {Event extraction for the biomedical domain is more challenging than that in the general news domain since it requires broader acquisition of domain-speciﬁc knowledge and deeper understanding of complex contexts. To better encode contextual information and external background knowledge, we propose a novel knowledge base (KB)-driven treestructured long short-term memory networks (Tree-LSTM) framework, incorporating two new types of features: (1) dependency structures to capture wide contexts; (2) entity properties (types and category descriptions) from external ontologies via entity linking. We evaluate our approach on the BioNLP shared task with Genia dataset and achieve a new stateof-the-art result. In addition, both quantitative and qualitative studies demonstrate the advancement of the Tree-LSTM and the external knowledge representation for biomedical event extraction.},
	language = {en},
	author = {Li, Diya and Huang, Lifu and Ji, Heng and Han, Jiawei},
	pages = {10},
	year = {2019},
	file = {Li 等。 - Biomedical Event Extraction based on Knowledge-dri.pdf:files/226/Li 等。 - Biomedical Event Extraction based on Knowledge-dri.pdf:application/pdf},
}

@inproceedings{chen_automatically_2017-1,
	address = {Vancouver, Canada},
	title = {Automatically {Labeled} {Data} {Generation} for {Large} {Scale} {Event} {Extraction}},
	url = {http://aclweb.org/anthology/P17-1038},
	doi = {10.18653/v1/P17-1038},
	abstract = {Modern models of event extraction for tasks like ACE are based on supervised learning of events from small hand-labeled data. However, hand-labeled training data is expensive to produce, in low coverage of event types, and limited in size, which makes supervised methods hard to extract large scale of events for knowledge base population. To solve the data labeling problem, we propose to automatically label training data for event extraction via world knowledge and linguistic knowledge, which can detect key arguments and trigger words for each event type and employ them to label events in texts automatically. The experimental results show that the quality of our large scale automatically labeled data is competitive with elaborately human-labeled data. And our automatically labeled data can incorporate with human-labeled data, then improve the performance of models learned from these data.},
	language = {en},
	urldate = {2020-08-20},
	booktitle = {Proceedings of the 55th {Annual} {Meeting} of the {Association} for           {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Chen, Yubo and Liu, Shulin and Zhang, Xiang and Liu, Kang and Zhao, Jun},
	year = {2017},
	pages = {409--419},
	file = {Chen 等。 - 2017 - Automatically Labeled Data Generation for Large Sc.pdf:files/227/Chen 等。 - 2017 - Automatically Labeled Data Generation for Large Sc.pdf:application/pdf},
}

@inproceedings{wang_adversarial_2019,
	address = {Minneapolis, Minnesota},
	title = {Adversarial {Training} for {Weakly} {Supervised} {Event} {Detection}},
	url = {http://aclweb.org/anthology/N19-1105},
	doi = {10.18653/v1/N19-1105},
	abstract = {Modern weakly supervised methods for event detection (ED) avoid time-consuming human annotation and achieve promising results by learning from auto-labeled data. However, these methods typically rely on sophisticated pre-deﬁned rules as well as existing instances in knowledge bases for automatic annotation and thus suffer from low coverage, topic bias, and data noise. To address these issues, we build a large event-related candidate set with good coverage and then apply an adversarial training mechanism to iteratively identify those informative instances from the candidate set and ﬁlter out those noisy ones. The experiments on two real-world datasets show that our candidate selection and adversarial training can cooperate together to obtain more diverse and accurate training data for ED, and signiﬁcantly outperform the state-of-theart methods in various weakly supervised scenarios. The datasets and source code can be obtained from https://github.com/ thunlp/Adv-ED.},
	language = {en},
	urldate = {2020-08-20},
	booktitle = {Proceedings of the 2019 {Conference} of the {North}},
	publisher = {Association for Computational Linguistics},
	author = {Wang, Xiaozhi and Han, Xu and Liu, Zhiyuan and Sun, Maosong and Li, Peng},
	year = {2019},
	pages = {998--1008},
	file = {Wang 等。 - 2019 - Adversarial Training for Weakly Supervised Event D.pdf:files/228/Wang 等。 - 2019 - Adversarial Training for Weakly Supervised Event D.pdf:application/pdf},
}

@article{wattarujeekrit_no_2004,
	title = {[{No} title found]},
	volume = {5},
	issn = {14712105},
	url = {http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-5-155},
	doi = {10.1186/1471-2105-5-155},
	abstract = {Background: The exploitation of information extraction (IE), a technology aiming to provide instances of structured representations from free-form text, has been rapidly growing within the molecular biology (MB) research community to keep track of the latest results reported in literature. IE systems have traditionally used shallow syntactic patterns for matching facts in sentences but such approaches appear inadequate to achieve high accuracy in MB event extraction due to complex sentence structure. A consensus in the IE community is emerging on the necessity for exploiting deeper knowledge structures such as through the relations between a verb and its arguments shown by predicate-argument structure (PAS). PAS is of interest as structures typically correspond to events of interest and their participating entities. For this to be realized within IE a key knowledge component is the definition of PAS frames. PAS frames for non-technical domains such as newswire are already being constructed in several projects such as PropBank, VerbNet, and FrameNet. Knowledge from PAS should enable more accurate applications in several areas where sentence understanding is required like machine translation and text summarization. In this article, we explore the need to adapt PAS for the MB domain and specify PAS frames to support IE, as well as outlining the major issues that require consideration in their construction.
Results: We introduce PASBio by extending a model based on PropBank to the MB domain. The hypothesis we explore is that PAS holds the key for understanding relationships describing the roles of genes and gene products in mediating their biological functions. We chose predicates describing gene expression, molecular interactions and signal transduction events with the aim of covering a number of research areas in MB. Analysis was performed on sentences containing a set of verbal predicates from MEDLINE and full text journals. Results confirm the necessity to analyze PAS specifically for MB domain.
Conclusions: At present PASBio contains the analyzed PAS of over 30 verbs, publicly available on the Internet for use in advanced applications. In the future we aim to expand the knowledge base to cover more verbs and the nominal form of each predicate.},
	language = {en},
	number = {1},
	urldate = {2020-08-20},
	journal = {BMC Bioinformatics},
	author = {Wattarujeekrit, Tuangthong and Shah, Parantu K and Collier, Nigel},
	year = {2004},
	pages = {155},
	file = {Wattarujeekrit 等。 - 2004 - [No title found].pdf:files/229/Wattarujeekrit 等。 - 2004 - [No title found].pdf:application/pdf},
}

@article{lee_ontology-based_2003,
	title = {Ontology-based fuzzy event extraction agent for {Chinese} e-news summarization},
	volume = {25},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417403000629},
	doi = {10.1016/S0957-4174(03)00062-9},
	abstract = {An Ontology-based Fuzzy Event Extraction (OFEE) agent for Chinese e-news summarization is proposed in this article. The OFEE agent contains Retrieval Agent (RA), Document Processing Agent (DPA) and Fuzzy Inference Agent (FIA) to perform the event extraction for Chinese e-news summarization. First, RA automatically retrieves Internet e-news periodically, stores them into the e-news repository, and sends them to DPA for document processing. Then, the DPA will utilize the Chinese Part-of-speech (POS) tagger provided by Chinese knowledge information processing group to process the retrieved e-news and ﬁlter the Chinese term set by Chinese term ﬁlter. Next, the FIA and Event Ontology Filter (EOF) extract the e-news event ontology based on the Chinese term set and domain ontology. Finally, the Summarization Agent (SA) will summarize the e-news by the extracted-event ontology. By the simulation, the proposed method can summarize the Chinese weather e-news effectively.},
	language = {en},
	number = {3},
	urldate = {2020-08-20},
	journal = {Expert Systems with Applications},
	author = {Lee, C},
	month = oct,
	year = {2003},
	pages = {431--447},
	file = {Lee - 2003 - Ontology-based fuzzy event extraction agent for Ch.pdf:files/230/Lee - 2003 - Ontology-based fuzzy event extraction agent for Ch.pdf:application/pdf},
}

@article{al-smadi_knowledge-based_2016,
	title = {Knowledge-based {Approach} for {Event} {Extraction} from {Arabic} {Tweets}},
	volume = {7},
	issn = {21565570, 2158107X},
	url = {http://thesai.org/Publications/ViewPaper?Volume=7&Issue=6&Code=ijacsa&SerialNo=63},
	doi = {10.14569/IJACSA.2016.070663},
	abstract = {Tweets provide a continuous update on current events. However, Tweets are short, personalized and noisy, thus raises more challenges for event extraction and representation. Extracting events out of Arabic tweets is a new research domain where few examples – if any – of previous work can be found. This paper describes a knowledge-based approach for fostering event extraction out of Arabic tweets. The approach uses an unsupervised rule-based technique for event extraction and provides a named entity disambiguation of event related entities (i.e. person, organization, and location). Extracted events and their related entities are populated to the event knowledge base where tagged tweets’ entities are linked to their corresponding entities represented in the knowledge base. Proposed approach was evaluated on a dataset of 1K Arabic tweets covering different types of events (i.e. instant events and interval events). Results show that the approach has an accuracy of, 75.9\% for event trigger extraction, 87.5\% for event time extraction, and 97.7\% for event type identification.},
	language = {en},
	number = {6},
	urldate = {2020-08-20},
	journal = {International Journal of Advanced Computer Science and Applications},
	author = {AL-Smadi, Mohammad and Qawasmeh, Omar},
	year = {2016},
	file = {AL-Smadi 和 Qawasmeh - 2016 - Knowledge-based Approach for Event Extraction from.pdf:files/231/AL-Smadi 和 Qawasmeh - 2016 - Knowledge-based Approach for Event Extraction from.pdf:application/pdf},
}

@article{kang_knowledge-based_2014,
	title = {Knowledge-based extraction of adverse drug events from biomedical text},
	volume = {15},
	issn = {1471-2105},
	url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-15-64},
	doi = {10.1186/1471-2105-15-64},
	abstract = {Background: Many biomedical relation extraction systems are machine-learning based and have to be trained on large annotated corpora that are expensive and cumbersome to construct. We developed a knowledge-based relation extraction system that requires minimal training data, and applied the system for the extraction of adverse drug events from biomedical text. The system consists of a concept recognition module that identifies drugs and adverse effects in sentences, and a knowledge-base module that establishes whether a relation exists between the recognized concepts. The knowledge base was filled with information from the Unified Medical Language System. The performance of the system was evaluated on the ADE corpus, consisting of 1644 abstracts with manually annotated adverse drug events. Fifty abstracts were used for training, the remaining abstracts were used for testing.
Results: The knowledge-based system obtained an F-score of 50.5\%, which was 34.4 percentage points better than the co-occurrence baseline. Increasing the training set to 400 abstracts improved the F-score to 54.3\%. When the system was compared with a machine-learning system, jSRE, on a subset of the sentences in the ADE corpus, our knowledge-based system achieved an F-score that is 7 percentage points higher than the F-score of jSRE trained on 50 abstracts, and still 2 percentage points higher than jSRE trained on 90\% of the corpus.
Conclusion: A knowledge-based approach can be successfully used to extract adverse drug events from biomedical text without need for a large training set. Whether use of a knowledge base is equally advantageous for other biomedical relation-extraction tasks remains to be investigated.},
	language = {en},
	number = {1},
	urldate = {2020-08-20},
	journal = {BMC Bioinformatics},
	author = {Kang, Ning and Singh, Bharat and Bui, Chinh and Afzal, Zubair and van Mulligen, Erik M and Kors, Jan A},
	month = dec,
	year = {2014},
	pages = {64},
	file = {Kang 等。 - 2014 - Knowledge-based extraction of adverse drug events .pdf:files/232/Kang 等。 - 2014 - Knowledge-based extraction of adverse drug events .pdf:application/pdf},
}

@article{sha_jointly_nodate,
	title = {Jointly {Extracting} {Event} {Triggers} and {Arguments} by {Dependency}-{Bridge} {RNN} and {Tensor}-{Based} {Argument} {Interaction}},
	abstract = {Event extraction plays an important role in natural language processing (NLP) applications including question answering and information retrieval. Traditional event extraction relies heavily on lexical and syntactic features, which require intensive human engineering and may not generalize to different datasets. Deep neural networks, on the other hand, are able to automatically learn underlying features, but existing networks do not make full use of syntactic relations. In this paper, we propose a novel dependency bridge recurrent neural network (dbRNN) for event extraction. We build our model upon a recurrent neural network, but enhance it with dependency bridges, which carry syntactically related information when modeling each word. We illustrates that simultaneously applying tree structure and sequence structure in RNN brings much better performance than only uses sequential RNN. In addition, we use a tensor layer to simultaneously capture the various types of latent interaction between candidate arguments as well as identify/classify all arguments of an event. Experiments show that our approach achieves competitive results compared with previous work.},
	language = {en},
	author = {Sha, Lei and Qian, Feng and Chang, Baobao and Sui, Zhifang},
	pages = {8},
	year = {2018},
	file = {Sha 等。 - Jointly Extracting Event Triggers and Arguments by.pdf:files/233/Sha 等。 - Jointly Extracting Event Triggers and Arguments by.pdf:application/pdf},
}

@inproceedings{wang_hmeae_2019-1,
	address = {Hong Kong, China},
	title = {{HMEAE}: {Hierarchical} {Modular} {Event} {Argument} {Extraction}},
	shorttitle = {{HMEAE}},
	url = {https://www.aclweb.org/anthology/D19-1584},
	doi = {10.18653/v1/D19-1584},
	abstract = {Existing event extraction methods classify each argument role independently, ignoring the conceptual correlations between different argument roles. In this paper, we propose a Hierarchical Modular Event Argument Extraction (HMEAE) model, to provide effective inductive bias from the concept hierarchy of event argument roles. Speciﬁcally, we design a neural module network for each basic unit of the concept hierarchy, and then hierarchically compose relevant unit modules with logical operations into a role-oriented modular network to classify a speciﬁc argument role. As many argument roles share the same high-level unit module, their correlation can be utilized to extract speciﬁc event arguments better. Experiments on real-world datasets show that HMEAE can effectively leverage useful knowledge from the concept hierarchy and signiﬁcantly outperform the stateof-the-art baselines. The source code can be obtained from https://github.com/ thunlp/HMEAE.},
	language = {en},
	urldate = {2020-08-20},
	booktitle = {Proceedings of the 2019 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and the 9th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({EMNLP}-{IJCNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Wang, Xiaozhi and Wang, Ziqi and Han, Xu and Liu, Zhiyuan and Li, Juanzi and Li, Peng and Sun, Maosong and Zhou, Jie and Ren, Xiang},
	year = {2019},
	pages = {5776--5782},
	file = {Wang 等。 - 2019 - HMEAE Hierarchical Modular Event Argument Extract.pdf:files/234/Wang 等。 - 2019 - HMEAE Hierarchical Modular Event Argument Extract.pdf:application/pdf},
}

@article{li_exploiting_nodate,
	title = {Exploiting {Background} {Information} {Networks} to {Enhance} {Bilingual} {Event} {Extraction} {Through} {Topic} {Modeling}},
	abstract = {In this paper we describe a novel approach of biased propagation based topic modeling to exploit global background knowledge for enhancing both the quality and portability of event extraction. The distributions of event triggers and arguments in topically-related documents are much more focused than those in a heterogeneous corpus. Based on this intuition, we apply topic modeling to automatically select training documents for annotation, and demonstrate it can signiﬁcantly reduce annotation cost in order to achieve comparable performance for two different languages and two different genres. In addition, we conduct cross-document inference within each topic cluster and show that our approach advances state-of-the-art.},
	language = {en},
	author = {Li, Hao and Ji, Heng and Deng, Hongbo and Han, Jiawei},
	pages = {8},
	year = {2019},
	file = {Li 等。 - Exploiting Background Information Networks to Enha.pdf:files/235/Li 等。 - Exploiting Background Information Networks to Enha.pdf:application/pdf},
}

@article{wang_maven_2020,
	title = {{MAVEN}: {A} {Massive} {General} {Domain} {Event} {Detection} {Dataset}},
	shorttitle = {{MAVEN}},
	url = {http://arxiv.org/abs/2004.13590},
	abstract = {Event detection (ED), which identiﬁes event trigger words and classiﬁes event types according to contexts, is the ﬁrst and most fundamental step for extracting event knowledge from plain text. Most existing datasets exhibit the following issues that limit further development of ED: (1) Small scale of existing datasets is not sufﬁcient for training and stably benchmarking increasingly sophisticated modern neural methods. (2) Limited event types of existing datasets lead to the trained models cannot be easily adapted to generaldomain scenarios. To alleviate these problems, we present a MAssive eVENt detection dataset (MAVEN), which contains 4, 480 Wikipedia documents, 117, 200 event mention instances, and 207 event types. MAVEN alleviates the lack of data problem and covers much more general event types. Besides the dataset, we reproduce the recent state-of-the-art ED models and conduct a thorough evaluation for these models on MAVEN. The experimental results and empirical analyses show that existing ED methods cannot achieve promising results as on the small datasets, which suggests ED in real world remains a challenging task and requires further research efforts. The dataset and baseline code will be released in the future to promote this ﬁeld.},
	language = {en},
	urldate = {2020-07-25},
	journal = {arXiv:2004.13590 [cs]},
	author = {Wang, Xiaozhi and Wang, Ziqi and Han, Xu and Jiang, Wangyi and Han, Rong and Liu, Zhiyuan and Li, Juanzi and Li, Peng and Lin, Yankai and Zhou, Jie},
	month = apr,
	year = {2020},
	note = {arXiv: 2004.13590},
	keywords = {Computer Science - Computation and Language},
	file = {Wang 等。 - 2020 - MAVEN A Massive General Domain Event Detection Da.pdf:files/312/Wang 等。 - 2020 - MAVEN A Massive General Domain Event Detection Da.pdf:application/pdf},
}

@inproceedings{sigletos_meta-learning_2003,
	title = {Meta-learning beyond classification: {A} framework for information extraction from the {Web}},
	shorttitle = {Meta-learning beyond classification},
	booktitle = {International {Workshop} \& {Tutorial} on {Adaptive} {Text} {Extraction} and {Mining} held in conjunction with the 14th {European} {Conference} on {Machine} {Learning} and the 7th {European} {Conference} on {Principles} and {Practice} of},
	publisher = {Citeseer},
	author = {Sigletos, Georgios and Paliouras, Georgios and Spyropoulos, Constantine D. and Stamatopoulos, Takis},
	year = {2003},
	pages = {58},
	file = {Meta-learning beyond classification A framework for information extraction from web.pdf:files/314/Meta-learning beyond classification A framework for information extraction from web.pdf:application/pdf},
}


@inproceedings{tong_improving_2020,
	address = {Online},
	title = {Improving {Event} {Detection} via {Open}-domain {Trigger} {Knowledge}},
	url = {https://www.aclweb.org/anthology/2020.acl-main.522},
	doi = {10.18653/v1/2020.acl-main.522},
	abstract = {Event Detection (ED) is a fundamental task in automatically structuring texts. Due to the small scale of training data, previous methods perform poorly on unseen/sparsely labeled trigger words and are prone to overﬁtting densely labeled trigger words. To address the issue, we propose a novel Enrichment Knowledge Distillation (EKD) model to leverage external open-domain trigger knowledge to reduce the in-built biases to frequent trigger words in annotations. Experiments on benchmark ACE2005 show that our model outperforms nine strong baselines, is especially effective for unseen/sparsely labeled trigger words. The source code is released on https://github.com/shuaiwa16/ekd.git.},
	language = {en},
	urldate = {2021-05-23},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Tong, Meihan and Xu, Bin and Wang, Shuai and Cao, Yixin and Hou, Lei and Li, Juanzi and Xie, Jun},
	year = {2020},
	pages = {5887--5897},
	file = {Tong 等。 - 2020 - Improving Event Detection via Open-domain Trigger .pdf:files/538/Tong 等。 - 2020 - Improving Event Detection via Open-domain Trigger .pdf:application/pdf},
}
